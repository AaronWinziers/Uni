\documentclass[10pt,a4paper]{scrreprt}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\author{Mitschrift von Aaron Winziers}
\title{Big Data Analytics}
\date{SS 2020 - Coronasemester}
\begin{document}
	\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%					Vorlesung					 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
\chapter{Introduction}
\section{3 Big Vs}
\begin{itemize}
	\item Volume
	\item Velocity - Data should be updated much more quickly - no longer work in batches
	\item Variety - Videos, text, from web etc
\end{itemize}


\paragraph{Veracity} joins the other 3 Vs nowadays

\section{Volume}
\begin{itemize}
	\item Average company has 100 TB of data
	\item 2.5 quintillion bytes created every day
	\item the amount of data created will be 300x greater in 2020 than 2005 (aggregate, estimate)
\end{itemize}

\subsection{Challenges created by data volume}
\begin{itemize}
	\item Efficient storage
	\item Efficiant process queries
	\item Efficient learning with models
	\item What hardware and software architecture is needed for this?
\end{itemize}


\section{Variety}
\begin{itemize}
	\item Data consists of different forms of data
\end{itemize}

\subsection{Challenges created by data variety}
\begin{itemize}
	\item Syntactic heterogeneity - understadning different data types and formats
	\item Semantic heterogeneity - Differnt representations forthe same information
		\subitem Name abreviations - John Smith, J Smith, (Smith, John), Jon Smithe
	\item The prev 2 issues need to be understood because we need to combine:
		\subitem information from many different sources
		\subitem different types of information
\end{itemize}


\section{Velocity}
\begin{itemize}
	\item The speed at which data is created and processed
	\item Data needs to be processed quickly or otherwise (sometimes) forgotten
\end{itemize}

\subsection{Challenges created by data velocity}
\begin{itemize}
	\item Extremely fast flow of information
	\item Assessing the value of incoming information and drop "unimportant" information
	\item Quick integration of new information
\end{itemize}


\section{Veracity}
\begin{itemize}
	\item Deals with the uncertainty of data
	\item Can you trust the data?
\end{itemize}

\subsection{Challenges created by data velocity}
\begin{itemize}
	\item Differnet kinds of data defects:
		\subitem Data may be invalid (broken sensors, bad software)
		\subitem Data may be biased and not reflect the true population
		\subitem Data may be manipulated
	\item Methods are needed to identify and "repair" data defects
\end{itemize}

\subsection{User-Generated Data}
\begin{itemize}
	\item Users may answer dishonestly or not take surveys seriously
	\item Users may try to purposely influence the results of surveys
	\item Must check the plausibility of the data before using	
\end{itemize}

\section{Real Life Scenarios}
Twitter and facebook have hella data to process
\subsection{Search engines}
\begin{itemize}
	\item Analysis of User behavior - related queries, useful books, etc.
	\item Result rankings need to be processed
	\item Voice query processing
	\item Question answering - not just returning web results
	\item Understanding images - Showing quick summarizing graphics
	\item Velocity - i.e. news needs to be current
\end{itemize}
\subsection{Online shops}
\begin{itemize}
	\item Further shopping suggestions
	\item Bundles that are often bought together
	\item Adjusting pricing
	\item Fraud detection - esp. in reviews
\end{itemize}


\section{Data Warehouse s Data Lake}
\subsection{Data warehouse}
\begin{itemize}
	\item Data is processed into schema before being pput into warehouse
	\item Data is structured
	\item Analytics are then performed on clean data
	\item Many decisions need to made in advance esp when deciding which data to keep
	\item Poor approach with dynamic data or with multiple sources (No guaranteed schema)
\end{itemize}

\subsection{Data Lake}
\begin{itemize}
	\item Unstructured data is gathered and stored
	\item To analyze, data is selected from data pool
	\item No decisions are made about what to keep
	\item ALL data interesting for analysis is kept - both self created and gathered
	\item All data stored in single system dedicated only to storing data
\end{itemize}

\subsection{Modern Big Data environment}
\begin{itemize}
	\item All data fed into data lake
	\item Regular analysis is sent to data warehouse
	\subitem Used for established mining processes
	\subitem Extract, transform, load
	\item Analytic sandbox
	\subitem more exploratory analysis
	\subitem Used for more flexibility
\end{itemize}

\section{Web scale computation}
\subsection{Why is volume an issue?}
\begin{itemize}
	\item Reading data from disks is slow - esp when only from one disk
	\item Reading must be performed in parallel
	\item Larger amounts of data are more difficult to process
	\item Web - scale computation
	\begin{itemize}
		\item Web crawlers gather large amounts of data (commoncrawl.org ~220TB)
		\item Required analyses:
		\subitem Document inversion - creating a search index
		\subitem PageRank
		\subitem Web log mining (identifying user behavior)
		\subitem Trend Mining - predicting upcoming topics 
	\end{itemize}
\end{itemize}
\subsection{Scaling computing power (Data centers)}
\begin{itemize}
	\item Buying many cheap computers often cheaper than  buying more powerful computers
	\item Buying more = scaling out
	\item Buying more powerful = scaling up
	\item Issues with scaling out
	\subitem Large number of machines -> many hardware failures, esp hard drive failures
	\subitem Distributed solutions and algorithms are required
\end{itemize} 

\section{Fallacies}
\subsection{Hardware failures}
\begin{itemize}
	\item Failures are common, not the exception
	\item With larger amounts of machines the probability that something will fail approaches 1
\end{itemize}

\subsection{Fallacies of Distributed Computing}
\begin{itemize}
	\item The network is reliable
	\item Latency is zero
	\item Bandwidth is infinite
	\item The network is secure
	\item Topology doesn't change
	\item There is one administrator
	\item Transport cost is zero
	\item The network is homogeneous
\end{itemize}

\subsection{Failure handling}
\begin{itemize}
	\item Failures happen at any time - needs to be compensated by algorithms
	\item Data can be replicated - in Hadoop in 3 locations
	\item The state of the information can be logged
	\item Tasks can be performed redundantly
\end{itemize}



\section{Hadoop}
\begin{itemize}
	\item De facto standard for web scale analytics
	\item Open source software for reliable and scalable distributed computing
	\item Uses simple programming models - code does not change between one and many machines
	
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%					Vorlesung					 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Data Quality}
\section{Intro}
\begin{itemize}
	\item Garbage produces garbage
	\item A model trained with bad data will produce bad results even with good data
\end{itemize}
	
\subsection{Dimensions of data quality}
\subsubsection{Completeness}
\begin{itemize}
	\item All expected data is available
	\item A sufficient amount of data is available
	\item Completeness is dependent on application
	\subitem Data insufficient for one question may still be used to answer another
	\item No objective measure
\end{itemize}

\subsubsection{Accuracy}
Clear

\subsubsection{Currency}
\begin{itemize}
	\item Is the data new enough for my application?
	\item Is new data added fast enough (goes to completeness)
\end{itemize}

\subsubsection{Consistency}
\begin{itemize}
	\item Conforms to an authority(isbn) \textbf{(or)}
	\item Does ot contradict itself
	\item Hard inconsistency:
	\subitem Binary decision(consistent or not)
	\subitem Relatively simple
	\item Soft inconsistency:
	\subitem Value looks suspicious
	\subitem May or may  not be correct
	\subitem Often related to other quality dimensions
\end{itemize}

\subsection{Differences to Classic data}
\begin{itemize}
	\item More heterogeneous (More variety \& from different sources)
	\item Changes faster (Velocity)
	\item Cannot reject bad data (goal is to gather as much as possible)
	\subitem Goal is to gather as much as possible
	\subitem Different projects/applications need access to the data and have different ideas to the quality of the data
\end{itemize}


\section{"Good old days"}
\begin{itemize}
	\item Define data constraints
	\item Check if data meets constraints
	\item Reject otherwise
\end{itemize}


\subsection{How to check consistency}
\paragraph{Data definitions:}
\begin{itemize}
	\item SQL constraints
	\item DTD/XML-Schema
\end{itemize}
\paragraph{Authorities:}
\begin{itemize}
	\item Standards (ISO 639, ISO 3166-2)
	\item Authority files (e.g. Placenames)
\end{itemize}


\subsection{Constraints}
\begin{itemize}
	\item Rules may become very generic (* is NOT a good constraint)
	\item Can become very specific (impossible to maintain)
	\item They were bad for classical data, horrible for big data
	\subitem Big data is even more heterogeneous and much more volatile
\end{itemize}
\paragraph{In big data}
\begin{itemize}
	\item Constant need for updating
	\item What happens with unexpected data?
\end{itemize}
\paragraph{Combining data pools}
\begin{itemize}
	\item Old approach meant migrating and rewriting old data
	\subitem Not feasible because of cost of changing and the speed at which rules change
	\subitem Each data provider has different rules and standards
\end{itemize}


\subsection{Rejecting data}
\begin{itemize}
	\item Data can no longer be rejected
	\item We don't know what is wrong
	\item We don't have time to fix it
	\item We may need the "bad" data later
\end{itemize}

\subsection{What to do}
\begin{itemize}
	\item Have a clear understanding of what good data is
	\item Filter bad data based on your current application
	\item Critically check your results
	\item Data lake => Filter => Processing => Results (can jump back in every step)
	\item New pipeline for every application
\end{itemize}

\section{Steps to answering a question}
\begin{enumerate}
	\item What are the data sets?
	\item Filtering
	\begin{itemize}
		\item What is the expected value range?
		\subitem Most often times must be answered by a domain expert
		\item Why is information missing? 
		\subitem Answer also depends on domain knowledge. There may be no answer.
		\item Is it okay that information is missing?
		\subitem Domain expert
		\item How much data is missing?
		\subitem Dunno
	\end{itemize}
\end{enumerate}

\subsection{Know your data}
\begin{itemize}
	\item Outlier detection / analysis
	\item Descriptive statistics
	\item Result visualization
\end{itemize}

\paragraph{Outliers}
\begin{itemize}
	\item Not all outliers are bad
	\item Decision can be made to accept the loss of good data through cutoff (like in dates)
	\item Statistical analysis can show problematic outliers and systematic problems
	\item It \textbf{cannot} find individual errors
	\item Processing affects answerable questions
\end{itemize}
\large{Do not filter the wrong data}
\large{Keep your bias out of the pipeline}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%					Vorlesung					 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Data Quality Part II - Author Name Disambiguation}
\section{Problem}
\begin{itemize}
	\item Direct references - multiple entities with same name
	\item Indirect references - Generally difficult - sensitive to context(time of quote i.e. Obama or Trump), sensitive to language (Monaco, Munich, München)
\end{itemize}

\section{Author name Disambiguation vs Named Entity Disambiguation}
\begin{itemize}
	\item AND is a simplification
	\item Always deals with persons (sometimes groups)
	\item Mentions are already extracted from text
	\item Information is already \textit{relatively} structured
	\item Goal is to have minimal homonyms and synonyms 
\end{itemize}

\section{Problems with using names}
\begin{itemize}
	\item Names change
	\subitem Change in cultural context - change in translation o.Ä.
	\subitem Marriage
	\subitem Visit Mecca - add Haj
\end{itemize}

\section{How to identify a person}
\begin{itemize}
	\item Use other properties:
	\begin{itemize}
		\item Coauthors
		\item Affiliations (Uni, research group etc)
		\item Topic (Research specialization)
	\end{itemize}
\end{itemize}

\subsection{However:}
\begin{itemize}
	\item Coauthors may also be synonyms/homonyms
	\item Data may be difficult to interpret - Universität vs Univerisity of
	\item Data may just be wrong
\end{itemize}

\subsection{Also possible:}
Use external IDs:
\begin{itemize}
	\item Authority IDs (National Libraries)
	\item Specialized IDs (Orchid)
	\item Third Party (email, twitter handle etc)
\end{itemize}

\section{Algorithmic solutions}
Two principal solutions:
\begin{itemize}
	\item Batch computations: compute a matching for all mentions at once
	\item Iterative approach: Add new mentions to the existing profiles
\end{itemize}

\subsection{Batch Computation}
\begin{enumerate}
	\item Extract features for each mention (Coauthors, affiliations, etc.)
	\item Calculate similarity value for all pairs of mentions $n^2/2$ values (very expensive)
	\begin{itemize}
		\item Cosine similarity
		\item Trained similarity
	\end{itemize}
	\item Clustering to create individual profiles
	\begin{itemize}
		\item Very low values can be ignored (don't need to evaluate the whole graph)
		\item Provides a bit of an issue
		\item Requires a lot of data
	\end{itemize}
\end{enumerate}

\paragraph{Pros and Cons}
Pro:
\begin{itemize}
	\item Ignores previous errors
	\item Treats new data and old data equally
\end{itemize}
Cons:
\begin{itemize}
	\item Slow
	\item Cannot run with every update
	\item Mentions can oscillate between entities
\end{itemize}

\paragraph{Blocking}
\begin{itemize}
	\item Makes matching faster
	\item Divides mentions by a simple rule (last name)
	\item Matching is run per block
\end{itemize}
Pro:
\begin{itemize}
	\item Simple to implement
	\item Improves speed (reduces required similarity values)
\end{itemize}
Cons:
\begin{itemize}
	\item Entities may land in different blocks -> never matched
	\item Introduces structural problems -> changed names will not match
\end{itemize}

\subsection{Iterative Approach}
\begin{itemize}
	\item Keep known profiles
	\item Search for best matching profile (or create new ones)
	\item May update existing profiles (combine previously separate profiles)
\end{itemize}
Pro:
\begin{itemize}
	\item Can reuse known data (That was expensive to compute)
	\item More reactive for new data
	\item Compares similarities to entire profile (not individual publications)
\end{itemize}
Cons:
\begin{itemize}
	\item Might still require blocking
	\item Propagates old errors
	\item Need to store profiles
	\item Needs to be able to correct profiles
\end{itemize}

\section{Evaluation}
\paragraph{2 Goals:}
\begin{itemize}
	\item Determine if matching is acceptable
	\item Find optimal configuration for algorithm (secondary but important)
\end{itemize}

\paragraph{Typical approach}
\begin{enumerate}
	\item Get a test collection
	\item Run Algorithm
	\item Analyze results
\end{enumerate}

\paragraph{Test collections}
consist of:
\begin{itemize}
	\item A list of mentions
	\item A predefined mapping between mentions and entities
\end{itemize}
Algorithm is good if it approaches the gold standard (defined in test collection)

\paragraph{Creating test collections is difficult:}
\begin{itemize}
	\item Use a predefined one
	\item Make your own
	\item Try to reuse data you already have
\end{itemize}

\paragraph{Predefined}
\begin{itemize}
	\item Make sure it matches your collections
	\item The features should be the same
	\item The features should carry the same weight
	\item Datasets may be unreliable 
\end{itemize}

\paragraph{Self made}
\begin{itemize}
	\item All the same issues as with predefined
	\item Need to be created (expensive)
	\item Need to prevent bias in creation (May forget an edge case)
	\item May not be transferable (Need to create multiple)
\end{itemize}

\paragraph{Reuse own data}
Pros:
\begin{itemize}
	\item Very cheap
	\item Covers wide array of cases
\end{itemize}
Cons:
\begin{itemize}
	\item Only works if data is correct
	\item Limited in scope (Wei Wang -> homonym)
\end{itemize}

\subsection{Evaluation}
\paragraph{Quality of results}
\begin{itemize}
	\item Standard methods (precision, recall, cluster alignment)
	\item Method must match application
\end{itemize}
B$^3$ is an example algorithm
\paragraph{Performance of algorithms}
\begin{itemize}
	\item How long does it take?
	\item What resources are needed?
	\item Is your collection large enough?
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%					Vorlesung					 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Hadoop Framework}
\section{Introduction}
\begin{itemize}
	\item Open source big data processing framework
	\item Focused on processing large data sets on clusters of computers
\end{itemize}

\section{Related Apache projects}
Get from VL Folien 3-6

\section{Distributed file system}
\begin{itemize}
	\item Idea is to move the computation to the data
	\subitem Aboids need for copying over network (slow)
	\item Files stored in large chunks in cluster
	\item \textbf{Namenode} tracks block location
	\item Computations should be performed on the node where the data is
\end{itemize}

\section{File storage and replication}
HDFS
\begin{itemize}
	\item Files are separated into blocks
	\item Blocks are units for computations (blocks are always processed as a whole)
	\item Default replicas = 3
	\item Replication occurs when blocks are filled -> goes in to replication pipeline
	\subitem Block is full -> contact NameNode -> send data to other DataNode -> DataNode forwards to third node
\end{itemize}

\section{MapReduce}
\subsection{Key idea}
\begin{itemize}
	\item Spread task of processing data
	\item According to map and reduce rules/functions
	\item Framework deals with node failures, load balancing etc
\end{itemize}

\subsection{Map phase}
\begin{itemize}
	\item Machines process the block that they contain
	\item Produce key-value pairs which are used to partition the data
	\item 1 map task per data block
	\item Applying function f not influenced by other computations
	\subitem Allows for parallel computing
	\item Order in which computations are performed also unimportant
\end{itemize}

\subsection{Reduce phase}
\begin{itemize}
	\item Data is aggregated for each key-group
	\item Should apply another function f and then an accumulator
\end{itemize}

\subsection{Distributed MapReduce}
\begin{itemize}
	\item Input data is already chunked -> easy to process with single map task
	\item Some data blocks to not fit uniformly into blocks -> some data will need to be read across boundaries
\end{itemize}

\paragraph{Key principle}
\begin{itemize}
	\item Apply map function on each of input splits in dedicated process (run in YARN Container)
	\item One function call / line in input split (at least for text data)
	\item Produces data with keys -> partitions are based on keys
\end{itemize}

\paragraph{Computation}
\begin{itemize}
	\item Master node coordinates computation
	\subitem Accepts job(task)
	\subitem Computes map and reduce tasks
	\subitem Selects and activates worker nodes
	\item Worker node
	\subitem For map: selected if close to data
	\subitem Consumes intermediate results and creates final output
\end{itemize}

\paragraph{Parallelization}
\begin{itemize}
	\item Map functions can run in parallel
	\item Reduce functions can run in parallel
	\item Bottleneck: Reduce cannot start before map is finished
\end{itemize}

\section{MapReduce Data Flow}
\begin{itemize}
	\item Data is split into Input splits (usually one HDFS block)
	\item One map task per input split (ideally at block location)
	\item Configurable number of reduce tasks
\end{itemize}

\paragraph{Each map task:}
\begin{itemize}
	\item Stores its output locally
	\item Creates as many partitions as there are reduce tasks, where all output data for an output key is  guaranteed to be in the same partition
	\item Sorts each output partition by key (values are stored next to each other)
\end{itemize}

\paragraph{Each reduce task:}
\begin{itemize}
	\item Is responsible for one key partition
	\item Copies the output for its partition from \textbf{all} map tasks
	\item Merges outpus, keeping sorted order intact
	\item Feeds values from same key to reduce function
	\item Writes output to HDFS (first local block, then replicated)
\end{itemize}

\subsection{Influencing data flow}
\begin{itemize}
	\item Tuples are sorted by key
	\item For a single key, teh tuples are not sorted
\end{itemize}
\paragraph{Composite keys}
Possible solutions (year,temp) example:
\begin{itemize}
	\item Custom partitioner w/ year as partition -> data is sent to same reducer, not to same reduce call
	\item Sort Comparator for sorting by temperature
\end{itemize}

\paragraph{Combiner} Pre processes data in the map phase to reduce need for copying data

\subsection{Compression in Hadoop}
\begin{itemize}
	\item Compression can be used to reduce input file size and increase the amount of data that can be stored
	\item Requires splittable compression
	\item Output files can also be compressed to save traffic
\end{itemize}

\section{Useful components}
\subsection{Input Formats}
\begin{itemize}
	\item Gathers input from documents
	\item Default is TextInputFormat (1 record/ line)
	\item Can be customized for structured data (xml, json, etc)
\end{itemize}

\subsection{Multiple Input Directories}
\begin{itemize}
	\item Each input can be handled differently
	\item Can have separate formats and Map classes
	\item Can write to different output directories as well
\end{itemize}

\subsection{Custom Data Types}
\begin{itemize}
	\item Output Objects can be written (pairs of integers, etc)
	\item Theoretically possible to encode everything as text -> difficult to parse -> not efficient
	\item Must implement WritableComparable
\end{itemize}

\section{YARN}
\begin{itemize}
	\item Offers two daemons:
	\subitem Resources manager - Manages usage of resources across cluster
	\subitem Node managers - run on all nodes to launch and monitor containers
	\item  Containers execute an application specific process with a set of resources (memory, CPU, etc)
	\item \textbf{Workflow can be seen on 3-74}
\end{itemize}
\subsection{Advantages of YARN}
\begin{itemize}
	\item Scalability
	\subitem ApplicationMaster manages containers for one application
	\item ResourceManager only deals with overall allocation of the node
	\item Can scale to 10,000 nodes and 100,000 Tasks
	\item High availability - for resource manager and application master
	\item Utilization
	\begin{itemize}
		\item Node manager manages a pool of resources, rather than a fixed number of slots (Hadoop v1)
		\item No dedicated slots for mappers and reducers, but flexible resources
		\item Fine grained resources - applications can specify needs per task
	\end{itemize}
	\item Multitenancy - can run other types of tasks
\end{itemize}

\subsection{Resources}
\begin{itemize}
	\item Resources can be configured locally
	\item Can include GPUs and FPGAs
\end{itemize}

\subsection{Schedulers}
\begin{itemize}
	\item FIFO
	\item Capacity scheduler
	\item Fair scheduler
\end{itemize}

\subsubsection{Capacity Scheduler}
\begin{itemize}
	\item Multiple independent queues
	\item Allows for sharing between organizations
	\item Each queue is given a fraction of the resources
	\item Individual queues are FIFO
	\item A single job does not use more resources than its queue's capacity
	\item Queues are elastic - Idle resources are distributed to other queues
	\item No preemption - Running jobs will finish
\end{itemize}

\subsubsection{Fair Scheduler}
\begin{itemize}
	\item Dynamically balances resources between all running jobs
	\item A single running job gets all resources
	\item A second task will get half of the resources
	\item By default only memory is considered for fairness, others can be configured
	\item Also works for multiple queues (3 tasks from 2 queues -> 2 x 1/4, 1x 1/2 of resources)
	\item Preemption can move tasks to idle queue, but will not kill tasks to restore fairness
\end{itemize}

\subsection{Failure Handling}
\begin{itemize}
	\item Automatic handling of failed tasks
	\item Most useful for transient failures (Hardware or software failures)
	\item Application Master manages task failures
	\subitem Exchanges progress updates
	\subitem Task is considered failed if no update for more than 10 min (even if still running)
	\subitem Restarts task in different container
	\subitem Repeated failures of the same task cause the job to fail
	\item YARN will restart failed applications
	\item ResourceManager restarts failed NodeManagers
\end{itemize}

\subsection{Speculative execution}
\begin{itemize}
	\item Some tasks may be slower than usual
	\subitem Hardware Issues
	\subitem Overloaded system
	\subitem More complex subsection of data
	\item YARN assumes transient problem and tries running slow tasks on other machines
	\item First finished task wins, other attempts are killed, output ignores
	\item Improves response time on single job at cost of load on cluster
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%					Vorlesung					 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{MapReduce and SQL}

y tho?
\section{Processing SQL Queries in MapReduce}
\begin{itemize}
	\item Given is a Relation (Table) stored in a file (1 tuple/line)
	\item Evaluating a query on this file using MR is a Map-Only job:
	\subitem Mapper only emits tuples that match the search predicate (WHERE clause)
	\item Queries become more interesting with GROUP BY, HAVING and AGGREGATE(ie avg) clauses
\end{itemize}

\section{Reduce side Join}
\begin{itemize}
	\item Send tuples with key of joining attribute
	\item Combine in reducer
	\item In large relations the copying can be very expensive, therefore map side reduce may be better
\end{itemize}

\section{Map-Side Join}
\begin{itemize}
	\item Assume one of the relations is small and can be loaded into main memory
	\item Mapper can create joined tuples from subset of second relation
\end{itemize}

\section{Optimized reduce side Join}
\begin{itemize}
	\item Analog to semi-join
	\item Assuming neither of the relations is small enough for main memory
	\item Load the unique values of joining attributes into main memory (One may be small enough for this)
	\item Map
	\begin{itemize}
		\item Knows unique values of joining attribute from one relation (R.B)
		\item Sends tuples from Relation R by with key joining attribute
		\item Tuples from other relation S only sent if joining attribute value can be found in relation R (4-11 if unclear)
	\end{itemize}
	\item Reduce then joins
\end{itemize}

\subsection{Global Sharing of Information}
\begin{itemize}
	\item Hadoop has a "Distributed Cache"
	\item Should be used for small amounts of data
	\item Is read at init of Mapper
\end{itemize}

\section{Bloom Filter}
\begin{itemize}
	\item Used if the unique values are still too many for main memory
	\item Is used to create compact representation of join attributes
	\item Bloom filters are very generic data structures with wide applications
\end{itemize}

\subsection{Structures}
\begin{itemize}
	\item Consists of a bit array of size m (all bits arre initially 0)
	\item Hash each distinct attribute value to a bucket and set bucket to 1
	\item This method may result in collisions
	\item Solution to collisions:
	\begin{itemize}
		\item Use multiple hash functions to reduce collisions
		\item Use all hash functions and set all buckets to 1
	\end{itemize}
	\item It is only possible to determine if the value \textit{may} be in the set(if all buckets = 1)
	\item Probability of false positives can be calculated (4-17)
	\item Trade off between compression and false positives must be considered
\end{itemize}

\subsection{Implications of false positives}
\begin{itemize}
	\item More network traffic than necessary
	\item More work for result
	\item No erroneous results - all needed tuples are created 
\end{itemize}

\section{Map-side Joing without distributed cache}
\begin{itemize}
	\item Only works if both relations are already sorted by key
	\item Mappers consume chunks from both relations with matching join values (each chunk contains all join partners)
	\item Use CompositeInputFormat in Hadoop
\end{itemize}

\section{MapReduce vs Traditional RDBMS}
\begin{table}[]
	\begin{tabular}{l|l|l}
		& Traditional RDBMS         & MapReduce                   \\ \hline
		Data Size & Gigabytes                 & Petabytes                   \\
		Access    & Interactive and Batch     & Batch                       \\
		Updates   & Read and write many times & Write once, read many times \\
		Structure & Static Schema             & Dynamic schema              \\
		Integrity & High                      & Low                         \\
		Scaling   & Non linear                & Linear                     
	\end{tabular}
\end{table}

\section{Benefits of MapReduce}
\begin{itemize}
	\item Simple model
	\item High scalability
	\item Aims at high throughput - speed for many jobs - not a single job
	\item Tolerant against node failures
\end{itemize}

\section{Limitations}
\begin{itemize}
	\item Low level routines - very near the data
	\item Can have slow response time for individual small tasks
	\item Complex queries can be a hassle
\end{itemize}



\end{document}



 



























